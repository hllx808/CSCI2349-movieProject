{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40eb15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "executionInfo": {
     "elapsed": 5078,
     "status": "ok",
     "timestamp": 1701735048749,
     "user": {
      "displayName": "David Chung",
      "userId": "13481739348252387839"
     },
     "user_tz": 300
    },
    "id": "bf40eb15",
    "outputId": "8bd37dc3-74f3-401a-b5b4-23809f76c4e3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# make sure you imported the kaggle dataset and have it on the same directory as this.\n",
    "file = \"../raw_data/wiki_movie_plots_deduped.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NxBNVWBj-Bm5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1233,
     "status": "ok",
     "timestamp": 1701735052271,
     "user": {
      "displayName": "David Chung",
      "userId": "13481739348252387839"
     },
     "user_tz": 300
    },
    "id": "NxBNVWBj-Bm5",
    "outputId": "f00197b6-e510-4581-d3f0-d707457c09b0"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ImxjYX2p3q3P",
   "metadata": {
    "id": "ImxjYX2p3q3P"
   },
   "outputs": [],
   "source": [
    "condition = df['Genre'] == \"romantic comedy\"\n",
    "romantic_df = df[condition]\n",
    "#romantic_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5242dea6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 1912,
     "status": "ok",
     "timestamp": 1701735055148,
     "user": {
      "displayName": "David Chung",
      "userId": "13481739348252387839"
     },
     "user_tz": 300
    },
    "id": "5242dea6",
    "outputId": "166516ee-087f-4670-8a49-a3d4dd03f907"
   },
   "outputs": [],
   "source": [
    "# This cell takes awhile to run\n",
    "\n",
    "selected_col = df[[\"Genre\", \"Plot\"]] # columns from the csv that we want to focus on\n",
    "\n",
    "selected_genres = [\"comedy\", \"drama\", \"adventure\", \"fantasy\",\n",
    "                  \"horror\", \"mystery\", \"romance\",\n",
    "                 \"action\", \"thriller\", \"western\"] # select 10 genres\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "movie = {}\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in selected_col.iterrows():\n",
    "    genre = row['Genre']\n",
    "    plot = row['Plot']\n",
    "\n",
    "    # Check if genre exists in selected_genres\n",
    "    if genre in selected_genres:\n",
    "        if genre in movie:\n",
    "            # Append the movie plot to the existing value\n",
    "            # I did < 250 to ensure that every genre has less than 250 movies. This is because we had too much\n",
    "            # text so I had to shorten it\n",
    "            if len(movie[genre]) < 250:\n",
    "                movie[genre].append(plot)\n",
    "        else:\n",
    "            # Create a new key-value pair\n",
    "            movie[genre] = [plot]\n",
    "\n",
    "\n",
    "\n",
    "# Right now, the result of movie looks like this:\n",
    "# movie = {comedy: [movie1, movie2, movie3,...,movie250], action: [movie1, movie2, movie3,...,movie250]} and so on\n",
    "\n",
    "# So the value of the key-value pairs is just a list of the movies\n",
    "\n",
    "# selected_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea54e47c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1701402006370,
     "user": {
      "displayName": "David Chung",
      "userId": "13481739348252387839"
     },
     "user_tz": 300
    },
    "id": "ea54e47c",
    "outputId": "df94581f-6f60-4457-9c1d-57ffbdb1bd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849167\n"
     ]
    }
   ],
   "source": [
    "# print total amount of words in entire text corpus that we are analyzing\n",
    "total_words = 0\n",
    "for key in movie:\n",
    "    for mov in movie[key]:\n",
    "        total_words += len(mov.split(' '))\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4dba732",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1701402008027,
     "user": {
      "displayName": "David Chung",
      "userId": "13481739348252387839"
     },
     "user_tz": 300
    },
    "id": "c4dba732",
    "outputId": "7844a610-b565-4d00-9e41-3e5727f722da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2454\n"
     ]
    }
   ],
   "source": [
    "# prints out the total amount of movies we are analyzing\n",
    "\n",
    "total_movies = 0\n",
    "for key in movie:\n",
    "    total_movies += len(movie[key])\n",
    "print(total_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e82f05",
   "metadata": {
    "id": "c7e82f05"
   },
   "outputs": [],
   "source": [
    "# So to get the text corpus for a particular genre, do something like:\n",
    "\n",
    "# text = movie[\"comedy\"]\n",
    "# because this 'text' variable is a list (because the value from the key-value pair is a list)\n",
    "# we want to make it a string\n",
    "# so do something like new_text = \"\".join(text)\n",
    "# get rid of stop words, normalize, lemmatize, etc, and make visualization from there\n",
    "\n",
    "text = movie[\"comedy\"]\n",
    "#print(type(text))\n",
    "new_text = \"\".join(text)\n",
    "#print(type(new_text))\n",
    "\n",
    "# get stop words\n",
    "# tokenize/lemmatize depending on what your doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ghDlpGdH9ZTs",
   "metadata": {
    "id": "ghDlpGdH9ZTs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions initialized!\n"
     ]
    }
   ],
   "source": [
    "#initializing bigram (and unigram) function\n",
    "def uniBigrams(text):\n",
    "  stoplist = stopwords.words('english')\n",
    "  stoplist.extend([\".\", \",\", \"?\", \"could\", \"would\", \"“\", \"”\", \"’\", \";\", \"!\", \"(\", \")\", \"'s\", \"[\", \"]\", '``', \"''\"])\n",
    "\n",
    "  alltokens = nltk.word_tokenize(text)\n",
    "  allcontenttokens = [w for w in alltokens if w.lower() not in stoplist]\n",
    "\n",
    "  from nltk.stem import WordNetLemmatizer\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "  # create a new list of tokens, alllemmas by lemmatizing allcontenttokens\n",
    "  all_lemmas = [lemmatizer.lemmatize(w) for w in allcontenttokens]\n",
    "\n",
    "  unigrams = nltk.ngrams(all_lemmas, 1)\n",
    "  unigramlist = list(unigrams)\n",
    "\n",
    "  bigrams = nltk.ngrams(all_lemmas, 2)\n",
    "  bigramlist = list(bigrams)\n",
    "\n",
    "  # print out most frequent bigrams and unigrams\n",
    "  bigramfreq = nltk.FreqDist(bigramlist)\n",
    "  unigramfreq = nltk.FreqDist(unigramlist)\n",
    "  maxBigrams = bigramfreq.most_common(5)\n",
    "  maxUnigrams = unigramfreq.most_common(20)\n",
    "  return [maxBigrams, maxUnigrams]\n",
    "\n",
    "print(\"functions initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wsNb20l_acfR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15097,
     "status": "ok",
     "timestamp": 1701735078967,
     "user": {
      "displayName": "David Chung",
      "userId": "13481739348252387839"
     },
     "user_tz": 300
    },
    "id": "wsNb20l_acfR",
    "outputId": "48f5a26e-de1b-4d01-f7fb-0f671330287e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comedy [(('young', 'man'), 40), (('young', 'woman'), 25), (('fall', 'love'), 25), (('New', 'York'), 18), (('Mrs.', 'Erlynne'), 17)]\n",
      "drama [(('described', 'film'), 60), (('film', 'magazine'), 57), (('fall', 'love'), 41), (('New', 'York'), 34), (('magazine', '3'), 21)]\n",
      "adventure [(('fall', 'love'), 31), (('Johnny', 'Pacific'), 23), (('United', 'States'), 19), (('next', 'day'), 17), (('de', 'Maynes'), 17)]\n",
      "fantasy [(('Little', 'Bear'), 37), (('next', 'day'), 33), (('fall', 'love'), 30), (('White', 'Snake'), 28), (('Green', 'Snake'), 24)]\n",
      "horror [(('Lady', 'Jane'), 62), (('next', 'day'), 49), (('next', 'morning'), 46), (('Sir', 'Frederick'), 40), (('Van', 'Helsing'), 28)]\n",
      "mystery [(('Lone', 'Wolf'), 40), (('New', 'York'), 32), (('Holmes', 'Watson'), 23), (('found', 'dead'), 22), (('Los', 'Angeles'), 21)]\n",
      "romance [(('New', 'York'), 76), (('fall', 'love'), 62), (('next', 'day'), 46), (('York', 'City'), 33), (('next', 'morning'), 25)]\n",
      "action [(('United', 'States'), 39), (('New', 'York'), 36), (('Red', 'Skull'), 36), (('Los', 'Angeles'), 34), (('gang', 'member'), 31)]\n",
      "thriller [(('New', 'York'), 62), (('next', 'day'), 44), (('York', 'City'), 28), (('Los', 'Angeles'), 28), (('Mrs.', 'Mott'), 25)]\n",
      "western [(('Gene', 'Autry'), 40), (('wagon', 'train'), 26), (('Autry', 'Gene'), 21), (('Smiley', 'Burnette'), 20), (('Gene', 'Frog'), 20)]\n"
     ]
    }
   ],
   "source": [
    "#Bigram finder\n",
    "for genre in selected_genres:\n",
    "  text = movie[genre]\n",
    "  new_text = \"\".join(text)\n",
    "  unibigram = uniBigrams(new_text)\n",
    "  actualBigram = unibigram[0]       #from the function it takes the maxBigrams object \n",
    "  print(genre, actualBigram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eURDYpH3cIeT",
   "metadata": {
    "id": "eURDYpH3cIeT"
   },
   "outputs": [],
   "source": [
    "def getText(genre):\n",
    "  text = movie[genre]\n",
    "  new_text = \"\".join(text)\n",
    "  return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "-UfJ7FIiaMcs",
   "metadata": {
    "id": "-UfJ7FIiaMcs"
   },
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "  stoplist = stopwords.words('english')\n",
    "  stoplist.extend([\".\", \",\", \"?\", \"could\", \"would\", \"“\", \"”\", \"’\", \";\", \"!\", \"(\", \")\", \"'s\", \"[\", \"]\", '``', \"''\"])\n",
    "\n",
    "  alltokens = nltk.word_tokenize(text)\n",
    "  allcontenttokens = [w for w in alltokens if w.lower() not in stoplist]\n",
    "\n",
    "  from nltk.stem import WordNetLemmatizer\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "  # create a new list of tokens, alllemmas by lemmatizing allcontenttokens\n",
    "  all_lemmas = [lemmatizer.lemmatize(w) for w in allcontenttokens]\n",
    "\n",
    "  return all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "oOl0jKXAZBTE",
   "metadata": {
    "id": "oOl0jKXAZBTE"
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "def collocations(genre):\n",
    "  text = getText(genre)\n",
    "  filtered_text = tokens(text)\n",
    "\n",
    "  bigram_finder = BigramCollocationFinder.from_words(filtered_text)\n",
    "  bigram_finder.apply_freq_filter(3)  # Adjust the frequency filter as needed\n",
    "\n",
    "  collocations = bigram_finder.nbest(BigramAssocMeasures.likelihood_ratio, 10)\n",
    "\n",
    "  # Print Collocations\n",
    "  print(\"Genre:\" + genre)\n",
    "  print(\"Collocations:\", collocations[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "T5VUDz18eHfG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13787,
     "status": "ok",
     "timestamp": 1701647960949,
     "user": {
      "displayName": "David Chung",
      "userId": "13481739348252387839"
     },
     "user_tz": 300
    },
    "id": "T5VUDz18eHfG",
    "outputId": "6eb165d2-928e-422e-8be5-c399dd54bcb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre:comedy\n",
      "Collocations: [('young', 'man'), ('New', 'York'), ('Mrs.', 'Erlynne')]\n",
      "Genre:drama\n",
      "Collocations: [('described', 'film'), ('film', 'magazine'), ('New', 'York')]\n",
      "Genre:adventure\n",
      "Collocations: [('United', 'States'), ('Johnny', 'Pacific'), ('fall', 'love')]\n",
      "Genre:fantasy\n",
      "Collocations: [('Little', 'Bear'), ('White', 'Snake'), ('Green', 'Snake')]\n",
      "Genre:horror\n",
      "Collocations: [('Lady', 'Jane'), ('Sir', 'Frederick'), ('next', 'morning')]\n",
      "Genre:mystery\n",
      "Collocations: [('Lone', 'Wolf'), ('New', 'York'), ('Los', 'Angeles')]\n",
      "Genre:romance\n",
      "Collocations: [('New', 'York'), ('fall', 'love'), ('York', 'City')]\n",
      "Genre:action\n",
      "Collocations: [('United', 'States'), ('Los', 'Angeles'), ('New', 'York')]\n",
      "Genre:thriller\n",
      "Collocations: [('New', 'York'), ('Los', 'Angeles'), ('next', 'day')]\n",
      "Genre:western\n",
      "Collocations: [('Gene', 'Autry'), ('Smiley', 'Burnette'), ('Millhouse', 'Smiley')]\n"
     ]
    }
   ],
   "source": [
    "for genre in selected_genres:\n",
    "  collocations(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5828546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
